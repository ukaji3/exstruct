# Benchmark Report

This report summarizes extraction accuracy for each method on the benchmark cases.
Scores are computed per case and aggregated by method. Exact, normalized, raw,
and markdown tracks are reported to ensure fair comparison across variations.

## Evaluation protocol (public)

Fixed settings for reproducibility:

- Model: gpt-4o (Responses API)
- Temperature: 0.0
- Prompt: fixed in bench/llm/openai_client.py
- Input contexts: generated by bench.cli extract
- Normalization: data/normalization_rules.json (optional track)
- Evaluation: bench.cli eval (Exact + Normalized + Raw)
- Markdown conversion: bench.cli markdown (optional)
- Report: bench.cli report (summary + per-case)

Recommended disclosure when publishing results:

- Model name + version, temperature, and date of run
- Full normalization_rules.json used for normalized scores
- Cost/token estimation method
- Any skipped cases and the reason (missing files, failures)

## How to interpret results (public guide)

- Exact: strict string match with no normalization.
- Normalized: applies case-specific rules in data/normalization_rules.json to
  absorb formatting differences (aliases, split/composite labels).
- Raw: loose coverage/precision over flattened text tokens (schema-agnostic).
- Markdown: coverage/precision against canonical Markdown rendered from truth.

Recommended interpretation:

- Use Exact to compare end-to-end string fidelity (best for literal extraction).
- Use Normalized to compare document understanding across methods.
- Use Raw to compare how much ground-truth text is captured regardless of schema.
- Use Markdown to evaluate JSON-to-Markdown conversion quality.
- When tracks disagree, favor Normalized for Excel-heavy layouts where labels
  are split/merged or phrased differently.
- Always cite both accuracy and cost metrics in public comparisons.

## Evaluation tracks

- Exact: strict string match without any normalization.
- Normalized: applies case-specific normalization rules (aliases, split/composite)
  defined in data/normalization_rules.json to absorb format and wording variations.
- Raw: loose coverage/precision over flattened text tokens (schema-agnostic),
  intended to reflect raw data capture without penalizing minor label variations.
- Markdown: coverage/precision comparing LLM Markdown to canonical truth Markdown.

## Summary by method

| method    |      acc |   avg_in |   avg_cost |   n |   acc_ordered |   acc_norm |   acc_norm_ordered |   acc_raw |   raw_precision |   acc_md |   md_precision |
|:----------|---------:|---------:|-----------:|----:|--------------:|-----------:|-------------------:|----------:|----------------:|---------:|---------------:|
| exstruct  | 0.583802 |  4620.75 | 0.0146977  |  12 |      0.579172 |   0.835538 |           0.806603 |  0.876495 |        0.933691 | 0.697269 |       0.796101 |
| html      | 0.377825 |  1812.75 | 0.00683187 |  12 |      0.37088  |   0.489698 |           0.477703 |  0.678979 |        0.751164 | 0.588284 |       0.717016 |
| image_vlm | 0.589282 |  1753.5  | 0.00716708 |  12 |      0.575678 |   0.756142 |           0.737136 |  0.824668 |        0.885373 | 0.661921 |       0.773776 |
| openpyxl  | 0.36789  |  2110.08 | 0.00733854 |  12 |      0.363261 |   0.481385 |           0.46939  |  0.671214 |        0.761695 | 0.581528 |       0.737017 |
| pdf       | 0.607551 |  1209.58 | 0.00592479 |  12 |      0.602921 |   0.856642 |           0.806294 |  0.874557 |        0.908698 | 0.700094 |       0.775776 |

## Markdown evaluation notes

Markdown scores measure how well the generated Markdown lines match a canonical
Markdown rendering of the ground truth JSON. This is a *conversion quality*
signal, not a direct extraction-accuracy substitute.

Key points:

- Coverage (acc_md): how much of truth Markdown content is recovered.
- Precision (md_precision): how much of predicted Markdown is correct.
- Layout shifts or list formatting differences can lower scores even if
  the underlying facts are correct.
- LLM-based conversion introduces variability; re-run with the same seed
  and model settings to assess stability, or use deterministic rendering
  for baseline comparisons.
- Use Markdown scores when your downstream task consumes Markdown (e.g.,
  RAG ingestion), and report alongside Exact/Normalized/Raw metrics.

## Exstruct positioning notes (public)

Recommended primary indicators for exstruct positioning (RAG pre-processing):

- Normalized accuracy: acc_norm / acc_norm_ordered
- Raw coverage/precision: acc_raw / raw_precision
- Markdown coverage/precision: acc_md / md_precision

Current deltas vs. best method (n=11, when available):

- Normalized accuracy: exstruct 0.835538 vs best 0.856642 (pdf), delta -0.021104
- Normalized ordered accuracy: exstruct 0.806603 vs best 0.806603 (exstruct), delta +0.000000
- Raw coverage: exstruct 0.876495 vs best 0.876495 (exstruct), delta +0.000000
- Raw precision: exstruct 0.933691 vs best 0.933691 (exstruct), delta +0.000000
- Markdown coverage: exstruct 0.697269 vs best 0.700094 (pdf), delta -0.002825
- Markdown precision: exstruct 0.796101 vs best 0.796101 (exstruct), delta +0.000000

## Normalization leniency summary

| case_id                      |   alias_rules |   split_rules |   composite_rules |   list_object_rules | details                                                                                |
|:-----------------------------|--------------:|--------------:|------------------:|--------------------:|:---------------------------------------------------------------------------------------|
| certificate_of_employment_01 |             1 |             0 |                 0 |                   0 | -                                                                                      |
| flowchart_02                 |             0 |             0 |                 0 |                   1 | steps(strings=step_type; strings_contains=step_name; lists_contains=-; strip_prefix=-) |
| heatstroke_flow_01           |             0 |             0 |                 0 |                   1 | steps(strings=step_name; strings_contains=-; lists_contains=-; strip_prefix=step_name) |
| tax_report_01                |             1 |             2 |                 2 |                   0 | -                                                                                      |
| workflow_01                  |             1 |             0 |                 0 |                   1 | steps(strings=step_name; strings_contains=-; lists_contains=-; strip_prefix=-)         |

## Detailed reports

- detailed_reports/report_basic_01.md
- detailed_reports/report_basic_form_01.md
- detailed_reports/report_certificate_of_employment_01.md
- detailed_reports/report_ffr_425_01.md
- detailed_reports/report_flowchart_01.md
- detailed_reports/report_flowchart_02.md
- detailed_reports/report_food_inspection_record_01.md
- detailed_reports/report_gantt_01.md
- detailed_reports/report_heatstroke_flow_01.md
- detailed_reports/report_smartart_01.md
- detailed_reports/report_tax_report_01.md
- detailed_reports/report_workflow_01.md
